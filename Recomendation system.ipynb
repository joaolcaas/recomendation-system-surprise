{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans,accuracy\n",
    "from surprise.model_selection import cross_validate,train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries we gonna use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_itens_by_id = dict()\n",
    "dict_id_by_itens = dict()\n",
    "watched = dict()\n",
    "wasnt_watched = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gettin all itens from the data base.\n",
    "    Arranging into a dictonary adding key=id and value=item_name\n",
    "'''\n",
    "itens = open('data/ml-100k/u.item',encoding=\"ISO-8859-1\")\n",
    "item_data = itens.read().split('\\n')\n",
    "for info in item_data:\n",
    "    split = info.split('|')\n",
    "    if(split != ['']):\n",
    "        id_item = (split[0])\n",
    "        film = (split[1])\n",
    "        dict_itens_by_id[id_item]=[film]\n",
    "\n",
    "        dict_id_by_itens[film]=id_item\n",
    "itens.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Getting films that user have been watched\n",
    "     Arranging into a dictonary adding key=id and value=item_name \n",
    "'''\n",
    "base = open('data/ml-100k/u1.base',encoding=\"ISO-8859-1\")\n",
    "item_base = base.read().split('\\n')\n",
    "for usr_info in item_base:\n",
    "    split = usr_info.split('\\t')\n",
    "    if(split != ['']):\n",
    "        key = split[0]\n",
    "        value = split[1]\n",
    "        if(key in watched):\n",
    "            watched[key].append(value)\n",
    "        else:\n",
    "            watched[key] = [value]\n",
    "base.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Getting films that user didnt watch\n",
    "     Arranging into a dictonary adding key=id and value=item_name \n",
    "'''\n",
    "films_list = set(dict_itens.keys())\n",
    "for i in watched:\n",
    "    films_list_user = set(watched[i])\n",
    "    wasnt_watched[i] = films_list.difference(films_list_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors <br></br>\n",
    "\n",
    "To train our model, we gonna use KNN algorithm. Using a option to do the train using cosine, after some operations into a graph, the KNN will return the nexts neighbors witch those are much like an other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN RMSE: 1.034\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Training our data using KNN\n",
    "'''\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "trainset,testset = train_test_split(data,test_size =.20)\n",
    "\n",
    "algo_KNN = KNNWithMeans(k=4, sim_options={'name': 'cosine', 'user_based': True})\n",
    "\n",
    "algo_KNN.fit(trainset)\n",
    "predictions_knn = algo_KNN.test(testset)\n",
    "print('KNN RMSE: %.3f' % accuracy.rmse(predictions_knn,verbose = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, as smaller the RMSE is, also smaller is the error. To our value, the error seems realy small, passing the impression that our prediction has no so much error.<br></br>\n",
    "\n",
    "And this value is pretty much equaly from the  <a href=\"http://surpriselib.com/\">Surprise.</a> \n",
    "\n",
    "So, taking that, looks our prediction to the films is gonna be great!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_5_films(uid):\n",
    "    '''\n",
    "    using the trained model for predict our filme users,\n",
    "        this function will return the top 5 films to the parse\n",
    "        user id\n",
    "        Args:\n",
    "        --------\n",
    "        uid: Id from User\n",
    "        Return:\n",
    "        -------\n",
    "        top_5: The 5 films most recomendaded to the uid\n",
    "    '''\n",
    "    predict = []\n",
    "    films_from_user = list(wasnt_watched[uid])\n",
    "\n",
    "    for i in films_from_user:\n",
    "        predict.append((i,algo_KNN.predict(uid=uid,iid=str(i)).est))\n",
    "    predict = sorted(predict, key=lambda x: x[1],reverse = True)\n",
    "    top_5 = predict[:5]\n",
    "    return top_5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_five(uid):\n",
    "    '''\n",
    "    Show the top five films to the user\n",
    "    Args:\n",
    "    --------\n",
    "        uid:Id from user\n",
    "    Return:\n",
    "    --------\n",
    "        top_five: list that contains the 5 itens to the user\n",
    "    '''\n",
    "    top_five = tuple()\n",
    "    first_five = get_5_films(uid)\n",
    "    for w in first_five:\n",
    "        print(dict_itens_by_id[w[0]],w[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can return a recomendation by a film:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_equaly_film(film_name):\n",
    "    '''\n",
    "        That function will return a film depending of \n",
    "            the entry film\n",
    "        Args:\n",
    "        --------\n",
    "            film_name: a film name and his date\n",
    "        Return:\n",
    "        --------\n",
    "            the name of the closest film\n",
    "    '''\n",
    "    film_raw_id = dict_id_by_itens[film_name]\n",
    "    film_inner_id = algo_KNN.trainset.to_inner_iid(film_raw_id)\n",
    "    return(dict_itens_by_id[str(film_inner_id)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples:<br></br>\n",
    "    <p>show_top_five('230')</p>\n",
    "    <p>show_equaly_film('Toy Story (1995)')</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mrs. Brown (Her Majesty, Mrs. Brown) (1997)'] 5\n",
      "['Titanic (1997)'] 5\n",
      "['Babe (1995)'] 5\n",
      "['Great Day in Harlem, A (1994)'] 5\n",
      "['L.A. Confidential (1997)'] 5\n"
     ]
    }
   ],
   "source": [
    "show_top_five('230')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bad Boys (1995)']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_equaly_film('Toy Story (1995)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:<br></br>\n",
    "\n",
    "As we see, my trainset and test set is no static. I always do the partition in train and test(80-20). So the resuls (hardely) will be the same twice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
